# Cluely-Lite ğŸ¤–

A **local, privacy-focused AI desktop assistant** for macOS that can see and interact with your screen using accessibility APIs and local AI models.

![Cluely-Lite Demo](https://img.shields.io/badge/macOS-14.0+-blue) ![Swift](https://img.shields.io/badge/Swift-5.0-orange) ![Python](https://img.shields.io/badge/Python-3.8+-green) ![Privacy](https://img.shields.io/badge/Privacy-100%25%20Local-brightgreen)

## âœ¨ Features

- **ğŸ¯ On-demand activation** - No continuous monitoring, only works when you invoke it
- **ğŸ”’ 100% Local** - All AI processing happens on your machine using Ollama
- **ğŸ‘ï¸ Screen awareness** - Uses macOS Accessibility APIs to understand your screen
- **âš¡ Quick access** - Press `âŒ˜+Return` or hover at top edge to activate
- **ğŸ›¡ï¸ Safety first** - Confirmation required for destructive actions
- **ğŸ¨ Beautiful UI** - Native macOS design with translucent overlay
- **ğŸ”§ Highly configurable** - Customizable models, hotkeys, and behavior

## ğŸš€ Quick Start

### 1. Install Ollama
```bash
curl -fsSL https://ollama.ai/install.sh | sh
ollama serve
ollama pull phi4:mini
```

### 2. Run Setup Script
```bash
git clone <your-repo-url>
cd cluely-lite
chmod +x setup.sh
./setup.sh
```

### 3. Grant Permissions
- **System Preferences** â†’ **Security & Privacy** â†’ **Privacy** â†’ **Accessibility**
- Add Cluely-Lite and check the box

### 4. Launch
```bash
./launch_cluely.sh
```

## ğŸ“– Usage

### Basic Commands
- **Press `âŒ˜+Return`** or **hover at top edge** to activate
- Type natural language commands:
  - "Click the Save button"
  - "Type 'Hello World' in the search box"
  - "Focus on the username field"
  - "What's on my screen right now?"
- When a potentially destructive action is detected you'll see a promptâ€”type `confirm` to proceed or `cancel` to abort.
- The overlay stays as a tiny pill at the top; hover your cursor to expand it or press the hotkey to interact.

### Available Actions
- **`answer`** - Provide text responses
- **`click`** - Click UI elements
- **`type`** - Type text into input fields
- **`focus`** - Focus on specific elements

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   macOS App     â”‚    â”‚  Python Server   â”‚    â”‚   Ollama AI     â”‚
â”‚                 â”‚    â”‚                  â”‚    â”‚                 â”‚
â”‚ â€¢ SwiftUI UI    â”‚â—„â”€â”€â–ºâ”‚ â€¢ HTTP Server    â”‚â—„â”€â”€â–ºâ”‚ â€¢ Local LLM     â”‚
â”‚ â€¢ Accessibility â”‚    â”‚ â€¢ Action Planner â”‚    â”‚ â€¢ Tool Planning â”‚
â”‚ â€¢ Hotkey Mgmt   â”‚    â”‚ â€¢ JSON Parser    â”‚    â”‚                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ”§ Configuration

### Environment Variables
```bash
# Use different AI model
export CLUELY_OLLAMA_MODEL="llama3.2:3b"

# Use different Ollama server
export CLUELY_OLLAMA_URL="http://localhost:11434/api/generate"

# Enable debug mode
export CLUELY_DEBUG=1
```

### Recommended Models
- **`phi4:mini`** - Fastest, ~2GB RAM, good for basic tasks
- **`llama3.2:3b`** - Balanced performance, ~3GB RAM
- **`qwen2.5:3b`** - Excellent for complex tasks, ~3GB RAM

## ğŸ› ï¸ Development

### Project Structure
```
cluely-lite/
â”œâ”€â”€ CluelyLite/              # macOS Swift app
â”‚   â”œâ”€â”€ CluelyLiteApp.swift  # Main app entry point
â”‚   â”œâ”€â”€ OverlayView.swift    # UI overlay
â”‚   â”œâ”€â”€ AgentClient.swift    # HTTP client
â”‚   â””â”€â”€ Accessibility*.swift # Screen interaction
â”œâ”€â”€ python/src/              # Python AI server
â”‚   â””â”€â”€ server.py           # HTTP server & AI logic
â”œâ”€â”€ setup.sh                # Automated setup
â”œâ”€â”€ test_server.py          # Server testing
â””â”€â”€ SETUP.md               # Detailed setup guide
```

### Building from Source
```bash
# Build macOS app
cd CluelyLite
xcodebuild -project CluelyLite.xcodeproj -scheme CluelyLite -configuration Release build

# Start Python server
cd python/src
python server.py
```

### Testing
```bash
# Test the server
python test_server.py

# Test with curl
curl -X POST http://127.0.0.1:8765/command \
  -H "Content-Type: application/json" \
  -d '{"instruction":"Click Save button"}'
```

## ğŸ”’ Privacy & Security

- **âœ… 100% Local Processing** - No data leaves your machine
- **âœ… No Telemetry** - No usage tracking or analytics
- **âœ… Open Source** - Full source code available for review
- **âœ… Minimal Permissions** - Only requests necessary accessibility access
- **âœ… No Cloud Dependencies** - Works completely offline

## ğŸ› Troubleshooting

### Common Issues

**"Accessibility permissions required"**
- Grant permissions in System Preferences â†’ Security & Privacy â†’ Privacy â†’ Accessibility

**"Ollama not detected"**
- Start Ollama: `ollama serve`
- Check model: `ollama list`
- Verify URL in server logs

**"Agent HTTP error"**
- Ensure Python server is running on port 8765
- Check firewall settings
- Review server logs

**App doesn't respond to hotkeys**
- Grant accessibility permissions
- Restart the app
- Check for conflicting hotkeys

### Debug Mode
```bash
# Enable debug logging
export CLUELY_DEBUG=1
python python/src/server.py
```

### Performance Tips
1. Use smaller models for faster responses
2. Close unnecessary applications
3. Use specific, clear instructions
4. Ensure adequate RAM (4GB+ recommended)

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch: `git checkout -b feature/amazing-feature`
3. Commit changes: `git commit -m 'Add amazing feature'`
4. Push to branch: `git push origin feature/amazing-feature`
5. Open a Pull Request

### Development Setup
```bash
# Clone and setup
git clone <your-fork>
cd cluely-lite
./setup.sh

# Run in development mode
cd python/src
python server.py &
cd ../../CluelyLite
xcodebuild -project CluelyLite.xcodeproj -scheme CluelyLite -configuration Debug build
```

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- **Ollama** - For providing excellent local LLM infrastructure
- **macOS Accessibility APIs** - For enabling screen interaction
- **SwiftUI** - For the beautiful native UI
- **Python** - For the robust server implementation

## ğŸ“ Support

- ğŸ“– **Documentation**: See [SETUP.md](SETUP.md) for detailed setup
- ğŸ› **Issues**: Report bugs on GitHub Issues
- ğŸ’¬ **Discussions**: Join GitHub Discussions for questions
- ğŸ“§ **Contact**: [Your contact information]

---

**Made with â¤ï¸ for privacy-conscious macOS users**

*Cluely-Lite: Your local AI assistant that respects your privacy.*